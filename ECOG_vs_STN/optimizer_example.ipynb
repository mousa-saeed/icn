{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from mne import Epochs\n",
    "from mne.decoding import SPoC\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_LM = [Real(0, 1, \"uniform\", name='alpha'),\n",
    "           Real(0, 1, \"uniform\", name='l1_ratio')]\n",
    "\n",
    "space_XGB = [Integer(1, 10, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Real(10**0, 10**1, \"uniform\", name=\"gamma\")]\n",
    "\n",
    "space_NN = [Real(low=1e-4, high=1e-2, prior='log-uniform', name='learning_rate'),\n",
    "              Integer(low=1, high=3, name='num_dense_layers'),\n",
    "              Integer(low=1, high=10, prior='uniform', name='num_input_nodes'),\n",
    "              Integer(low=1, high=10, name='num_dense_nodes'),\n",
    "              Categorical(categories=['relu', 'tanh'], name='activation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_enet(x,y):\n",
    "\n",
    "    @use_named_args(space_LM)\n",
    "    def objective(**params):\n",
    "        reg=ElasticNet(max_iter=1000, normalize=False)\n",
    "        reg.set_params(**params)\n",
    "        cval = cross_val_score(reg, x, y, scoring='r2', cv=3)\n",
    "        cval[np.where(cval < 0)[0]] = 0\n",
    "\n",
    "        return -cval.mean()\n",
    "\n",
    "    res_gp = gp_minimize(objective, space_LM, n_calls=20, random_state=0)\n",
    "    return res_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### read a real data stream file \n",
    "PATH_dat = \"C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\\\MOVEMENT DATA\\\\derivatives\\\\Int_old_grid\\\\sub_003_sess_right_run_4.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ = np.load(PATH_dat, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vhdr_file', 'resamplingrate', 'BIDS_path', 'projection_grid', 'bv_raw', 'ch_names', 'data_', 'subject', 'run', 'sess', 'sess_right', 'used_channels', 'coord_patient', 'proj_matrix_run', 'fs', 'line_noise', 'seglengths', 'normalization_samples', 'new_num_data_points', 'downsample_idx', 'filter_fun', 'offset_start', 'arr_act_grid_points', 'rf_data_median', 'pf_data_median', 'raw_label_baseline', 'label_baseline_corrected', 'label_baseline_corrected_onoff', 'label', 'label_con_true'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_time_dim(arr, y_, time_stamps):\n",
    "    \"\"\"\n",
    "    apply added time dimension for the data array and label given time_stamps (with downsample_rate=100) in 100ms / need to check with 1375Hz\n",
    "    \"\"\"\n",
    "    time_arr = np.zeros([arr.shape[0]-time_stamps, int(time_stamps*arr.shape[1])])\n",
    "    for time_idx, time_ in enumerate(np.arange(time_stamps, arr.shape[0])):\n",
    "        for time_point in range(time_stamps):\n",
    "            time_arr[time_idx, time_point*arr.shape[1]:(time_point+1)*arr.shape[1]] = arr[time_-time_point,:]\n",
    "    return time_arr, y_[time_stamps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STN_RIGHT_0',\n",
       " 'STN_RIGHT_1',\n",
       " 'STN_RIGHT_2',\n",
       " 'ECOG_RIGHT_0',\n",
       " 'ECOG_RIGHT_1',\n",
       " 'ECOG_RIGHT_2',\n",
       " 'ECOG_RIGHT_3',\n",
       " 'ECOG_RIGHT_4',\n",
       " 'ECOG_RIGHT_5',\n",
       " 'ECOG_RIGHT_6',\n",
       " 'ECOG_RIGHT_7',\n",
       " 'MOV_RIGHT',\n",
       " 'MOV_LEFT']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_[\"ch_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_[\"rf_data_median\"][:,0,:] # ch 0 STN_RIGHT_0\n",
    "y = raw_[\"label_baseline_corrected\"][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = append_time_dim(X, y, time_stamps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.135183535179675, tolerance: 0.0014794045058607037\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.472250847507858, tolerance: 0.0017448064728221354\n",
      "  positive)\n",
      "C:\\Users\\ICN_admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.127917521893236, tolerance: 0.002518985599938124\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optimize_enet(x=X_,y=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          fun: -0.013070825225774296\n",
       "    func_vals: array([-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.01307083, -0.01307083, -0.01307083, -0.01307083, -0.01307083,\n",
       "       -0.01005173, -0.01307083, -0.01093016, -0.        , -0.01164654])\n",
       "       models: [GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396)]\n",
       " random_state: <mtrand.RandomState object at 0x000002997253D408>\n",
       "        space: Space([Real(low=0, high=1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0, high=1, prior='uniform', transform='normalize')])\n",
       "        specs: {'args': {'func': <function optimize_enet.<locals>.objective at 0x0000029972E2CD38>, 'dimensions': Space([Real(low=0, high=1, prior='uniform', transform='normalize'),\n",
       "       Real(low=0, high=1, prior='uniform', transform='normalize')]), 'base_estimator': GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1], nu=2.5),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=209652396), 'n_calls': 20, 'n_random_starts': None, 'n_initial_points': 10, 'initial_point_generator': 'random', 'acq_func': 'gp_hedge', 'acq_optimizer': 'auto', 'x0': None, 'y0': None, 'random_state': <mtrand.RandomState object at 0x000002997253D408>, 'verbose': False, 'callback': None, 'n_points': 10000, 'n_restarts_optimizer': 5, 'xi': 0.01, 'kappa': 1.96, 'n_jobs': 1, 'model_queue_size': None}, 'function': 'base_minimize'}\n",
       "            x: [1.0, 0.0]\n",
       "      x_iters: [[0.5928446182250184, 0.8442657485810175], [0.857945617622757, 0.8472517387841256], [0.6235636967859725, 0.38438170729269994], [0.29753460654447234, 0.056712977317443194], [0.27265629458011326, 0.47766511732135], [0.8121687287754934, 0.47997717237505744], [0.39278479610082984, 0.8360787635373778], [0.33739616041726844, 0.6481718720511973], [0.368241539840548, 0.9571551589530466], [0.14035078041264518, 0.8700872583584366], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.010907828770443719, 0.007515565349455857], [1.0, 0.0], [0.006656693121470882, 0.00229181926442279], [0.9834825712445026, 0.9989194663154373], [0.003029285648648351, 0.0015299458916026025]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
